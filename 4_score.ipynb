{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Scenarios\n",
    "\n",
    "Run the cells below to score the configured scenarios. Any unscored scenarios will be scored.\n",
    "\n",
    "To re-score a scenario, open its corresponding file geodatabase and delete its `scores` and `scores_summary` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:08:38.629762Z",
     "start_time": "2021-12-23T22:08:38.622899Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'ato_tools' in sys.modules:\n",
    "    import importlib\n",
    "    importlib.reload(ato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:32:24.449765Z",
     "start_time": "2021-12-23T22:32:24.443433Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "import pandas as pd\n",
    "from arcgis.features import SpatialDataFrame\n",
    "\n",
    "src = os.path.join(os.path.abspath(\".\"), 'src')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)\n",
    "    \n",
    "from ato_tools import ato\n",
    "\n",
    "if 'ato_tools' in sys.modules:\n",
    "    import importlib\n",
    "    importlib.reload(ato)\n",
    "\n",
    "base_path = os.path.abspath(\".\")\n",
    "\n",
    "baseline_gdb = \"baseline.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:32:29.411568Z",
     "start_time": "2021-12-23T22:32:28.221085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\wfrc\\ato\\scenario\\Cycling\\13400_south_bike_lane.gdb\n",
      "C:\\wfrc\\ato\\scenario\\Cycling\\4700_south_bike_lane.gdb\n",
      "C:\\wfrc\\ato\\scenario\\Driving\\new_2700_west_overpass.gdb\n",
      "C:\\wfrc\\ato\\scenario\\Transit\\box_elder_express.gdb\n"
     ]
    }
   ],
   "source": [
    "modes = list()\n",
    "for file in os.listdir(r'scenario'):\n",
    "    d = os.path.join(base_path, r'scenario', file)\n",
    "    if os.path.isdir(d) and not d.endswith('.gdb'):\n",
    "        modes.append(file)\n",
    "\n",
    "to_score = list()\n",
    "for mode in ['Cycling', 'Driving', 'Transit']:\n",
    "    scenario_folder = os.path.join('scenario', mode)\n",
    "    for file in os.listdir(scenario_folder):\n",
    "        d = os.path.join(base_path, scenario_folder, file)\n",
    "        if os.path.isdir(d) and d.endswith('.gdb'):\n",
    "            if arcpy.Exists(os.path.join(d, 'scores')) == False:\n",
    "                print(d)\n",
    "                to_score.append((d, mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# score unscored networks\n",
    "\n",
    "# if testing, use a subset of centroids\n",
    "#if test:\n",
    "#    centroids = r\"shp\\taz_wfrc.gdb\\taz_centroids_sample\"\n",
    "\n",
    "\n",
    "for scenario in to_score:\n",
    "    gdb, mode = scenario\n",
    "    ato.skim(\n",
    "        gdb = gdb,\n",
    "        mode = mode,\n",
    "        skim_matrix = os.path.join(gdb, r\"skim_matrix\")\n",
    "    )\n",
    "    ato.score(\n",
    "        gdb = gdb\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the loop above fails due to an invalid network, you can rebuild the network by running `network.build()` on the full network dataset path, e.g. `network.build(r'scenario\\Transit\\ogden_local_bus.gdb\\NetworkDataset\\NetworkDataset_ND')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T21:34:19.773310Z",
     "start_time": "2021-12-23T21:34:19.737113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\wfrc\\ato\\scenario\\land_use\\ogden_cbd.gdb\n"
     ]
    }
   ],
   "source": [
    "# add land use projects\n",
    "to_score = list()\n",
    "scenario_folder = os.path.join('scenario', 'land_use')\n",
    "for file in os.listdir(scenario_folder):\n",
    "    d = os.path.join(base_path, scenario_folder, file)\n",
    "    if os.path.isdir(d) and d.endswith('.gdb'):\n",
    "        if arcpy.Exists(os.path.join(d, 'scores')) == False:\n",
    "            print(d)\n",
    "            to_score.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:17:54.539188Z",
     "start_time": "2021-12-23T22:17:03.326292Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores written to C:\\wfrc\\ato\\scenario\\land_use\\ogden_cbd.gdb\\ato_driving\n",
      "Network ATO: 625012823.0\n",
      "Scores written to C:\\wfrc\\ato\\scenario\\land_use\\ogden_cbd.gdb\\ato_cycling\n",
      "Network ATO: 92704904.0\n",
      "Scores written to C:\\wfrc\\ato\\scenario\\land_use\\ogden_cbd.gdb\\ato_transit\n",
      "Network ATO: 45464197.0\n",
      "Composite ATO 763181924.0 written to ato_comp\n",
      "Scenario score: 1487432.0\n"
     ]
    }
   ],
   "source": [
    "#score land use projects\n",
    "for gdb in to_score:\n",
    "\n",
    "    ato.score(\n",
    "        gdb = gdb,\n",
    "        skim_matrix = os.path.join(baseline_gdb, r\"skim_driving\"), \n",
    "        job_per_hh = 1.808755,\n",
    "        out_table = os.path.join(gdb, r\"ato_driving\")\n",
    "    )\n",
    "    \n",
    "    ato.score(\n",
    "        gdb = gdb,\n",
    "        skim_matrix = os.path.join(baseline_gdb, r\"skim_cycling\"), \n",
    "        job_per_hh = 1.808755,\n",
    "        out_table = os.path.join(gdb, r\"ato_cycling\")\n",
    "    )\n",
    "        \n",
    "    ato.score(\n",
    "        gdb = gdb,\n",
    "        skim_matrix = os.path.join(baseline_gdb, r\"skim_transit\"), \n",
    "        job_per_hh = 1.808755,\n",
    "        out_table = os.path.join(gdb, r\"ato_transit\")\n",
    "    )\n",
    "    \n",
    "    ato.comp(gdb = gdb) # create composite by combining ato scores per mode\n",
    "    \n",
    "    # calculate difference between scenario ATO and baseline\n",
    "    ato.diff(\n",
    "        baseline = r'baseline.gdb\\ato_comp', \n",
    "        scenario = os.path.join(gdb, 'ato_comp'),\n",
    "        out_table = os.path.join(gdb, 'scores')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate Scores Across Scenarios\n",
    "\n",
    "The cells below read in the scores from all scored scenarios and combined into a single summary table (`scenario\\scenario_scores.csv`)\n",
    "\n",
    "Scores for individual projects can be extracted from the `scores_summary` table within each file geodatabase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_long = pd.DataFrame(columns = ['Name', 'Mode', 'hh', 'jobs', 'ato'])\n",
    "\n",
    "vals = {\n",
    "    \"Name\":\"Baseline\",\n",
    "    \"Mode\": \"Auto\",\n",
    "    \"hh\": baseline_auto['accessible_hh'].sum(),\n",
    "    \"jobs\": baseline_auto['accessible_jobs'].sum(),\n",
    "    \"ato\": baseline_auto['ato'].sum()\n",
    "}\n",
    "summary_long = summary_long.append(vals, ignore_index=True)\n",
    "\n",
    "vals = {\n",
    "    \"Name\": \"Baseline\",\n",
    "    \"Mode\": \"Transit\",\n",
    "    \"hh\": baseline_transit['accessible_hh'].sum(),\n",
    "    \"jobs\": baseline_transit['accessible_jobs'].sum(),\n",
    "    \"ato\": baseline_transit['ato'].sum()\n",
    "}\n",
    "summary_long = summary_long.append(vals, ignore_index=True)\n",
    "\n",
    "vals = {\n",
    "    \"Name\": \"Baseline\",\n",
    "    \"Mode\": \"Cycling\",\n",
    "    \"hh\": baseline_cycling['accessible_hh'].sum(),\n",
    "    \"jobs\": baseline_cycling['accessible_jobs'].sum(),\n",
    "    \"ato\": baseline_cycling['ato'].sum()\n",
    "}\n",
    "summary_long = summary_long.append(vals, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = list()\n",
    "\n",
    "for mode in ['Driving', 'Transit', 'Cycling', 'Land_Use']:\n",
    "    scenario_folder = os.path.join('scenario', mode)\n",
    "    for file in os.listdir(scenario_folder):\n",
    "        d = os.path.join(scenario_folder, file)\n",
    "        if os.path.isdir(d) and d.endswith('.gdb'):\n",
    "            if arcpy.Exists(os.path.join(d, 'scores')) == True:\n",
    "                scenarios.append({\n",
    "                                \"name\": file[:-4],\n",
    "                                \"mode\": mode,\n",
    "                                \"gdb_path\": d\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    \n",
    "    arr = arcpy.da.TableToNumPyArray(scenario['gdb_path'] + r'\\scores_summary', field_list)\n",
    "    scores = pd.DataFrame(arr, columns = field_list)\n",
    "    \n",
    "    mode = scenario['mode']\n",
    "    \n",
    "    if mode == 'Driving':\n",
    "        baseline = r'baseline.gdb\\ato_driving'\n",
    "    elif mode == 'Transit':\n",
    "        baseline = r'baseline.gdb\\ato_transit'\n",
    "    elif mode == 'Cycling':\n",
    "        baseline = r'baseline.gdb\\ato_cycling'\n",
    "    elif mode == 'Land_Use':\n",
    "        baseline = r'baseline.gdb\\ato_comp'\n",
    "    \n",
    "    df = pd.merge(\n",
    "        baseline, \n",
    "        scores, \n",
    "        on='CO_TAZID', \n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_before\", \"_after\")\n",
    "    )\n",
    "    df['diff_hh'] = df['accessible_hh_after'] - df['accessible_hh_before']\n",
    "    df['diff_jobs'] = df['accessible_jobs_after'] - df['accessible_jobs_before']\n",
    "    df['diff_ato'] = df['ato_after'] - df['ato_before']\n",
    "    vals = {\n",
    "        \"Name\": scenario['name'],\n",
    "        'Mode': mode,\n",
    "        \"hh\": df['diff_hh'].sum(),\n",
    "        \"jobs\": df['diff_jobs'].sum(),\n",
    "        \"ato\": df['diff_ato'].sum()\n",
    "    }\n",
    "    \n",
    "    summary_long = summary_long.append(vals, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_long.to_csv(r'scenario\\scenario_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
